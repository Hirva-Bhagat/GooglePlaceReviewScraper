{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled18.ipynb",
      "provenance": [],
      "mount_file_id": "1CDs2gGpZzL-5Obxeyx6qPuN_Cc53RDv8",
      "authorship_tag": "ABX9TyN+zXqttQ0nog+Dadd2LSVJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hirva-Bhagat/GooglePlaceReviewScraper/blob/master/Bigram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPmge7GR2f__",
        "outputId": "0e0bf916-3b34-4364-be7b-9d4df2f1065a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('reuters') # one time execution\n",
        "nltk.download('punkt')  # one time execution\n",
        "\n",
        "from nltk.corpus import reuters\n",
        "import math\n",
        "import random"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALLAxi4-5LNF",
        "outputId": "83a09ebd-faa9-46e5-f20f-94c58e20a682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset_sents = reuters.sents()\n",
        "# print first sentence\n",
        "dataset_sents[1]\n",
        "\n",
        "# get list of words\n",
        "dataset_words = reuters.words()\n",
        "# print first word\n",
        "dataset_words[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX-ObJOc5RRI"
      },
      "source": [
        "data_sents = dataset_sents[:40000]\n",
        "data_sents_test = dataset_sents[40000:]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfNOzgoO5YPW"
      },
      "source": [
        "# number of words in train data\n",
        "num_words = 0\n",
        "for sentence in data_sents:\n",
        "  num_words += len(sentence)\n",
        "num_words\n",
        "# create two lists containing words\n",
        "data_words_train = dataset_words[:num_words]\n",
        "data_words_test = dataset_words[num_words:]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbCiyO675duV"
      },
      "source": [
        "def createBigram(data):\n",
        "\tlistOfBigrams = []\n",
        "\tbigramCounts = {}\n",
        "\tunigramCounts = {}\n",
        "\n",
        "\tfor i in range(len(data)):\n",
        "\t\tif i < len(data) - 1:\n",
        "\n",
        "\t\t\tlistOfBigrams.append((data[i], data[i + 1]))\n",
        "\n",
        "\t\t\tif (data[i], data[i+1]) in bigramCounts:\n",
        "\t\t\t\tbigramCounts[(data[i], data[i + 1])] += 1\n",
        "\t\t\telse:\n",
        "\t\t\t\tbigramCounts[(data[i], data[i + 1])] = 1\n",
        "\n",
        "\t\tif data[i] in unigramCounts:\n",
        "\t\t\tunigramCounts[data[i]] += 1\n",
        "\t\telse:\n",
        "\t\t\tunigramCounts[data[i]] = 1\n",
        "\n",
        "\treturn listOfBigrams, unigramCounts, bigramCounts"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs1vIxBk5hbL"
      },
      "source": [
        "def calcBigramProb(listOfBigrams, unigramCounts, bigramCounts):\n",
        "\n",
        "\tlistOfProb = {}\n",
        "\tfor bigram in listOfBigrams:\n",
        "\t\tword1 = bigram[0]\n",
        "\t\tword2 = bigram[1]\n",
        "\t\t\n",
        "\t\tlistOfProb[bigram] = (bigramCounts.get(bigram))/(unigramCounts.get(word1))\n",
        "\n",
        "\tfile = open('bigramProb.txt', 'w')\n",
        "\tfile.write('Bigram' + '\\t\\t\\t' + 'Count' + '\\t' + 'Probability' + '\\n')\n",
        "\n",
        "\tfor bigrams in listOfBigrams:\n",
        "\t\tfile.write(str(bigrams) + ' : ' + str(bigramCounts[bigrams]) + ' : ' + str(listOfProb[bigrams]) + '\\n')\n",
        "\tfile.close()\n",
        "\n",
        "\treturn listOfProb"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHkLCsKB5ptx"
      },
      "source": [
        "def bigramWithAddOneSmoothing(listOfBigrams, unigramCounts, bigramCounts):\n",
        "\n",
        "\tlistOfProb = {}\n",
        "\tcStar = {}\n",
        "\n",
        "\n",
        "\tfor bigram in listOfBigrams:\n",
        "\t\tword1 = bigram[0]\n",
        "\t\tword2 = bigram[1]\n",
        "\t\tlistOfProb[bigram] = (bigramCounts.get(bigram) + 1)/(unigramCounts.get(word1) + len(unigramCounts))\n",
        "\t\tcStar[bigram] = (bigramCounts[bigram] + 1) * unigramCounts[word1] / (unigramCounts[word1] + len(unigramCounts))\n",
        "\n",
        "\tfile = open('addOneSmoothing.txt', 'w')\n",
        "\tfile.write('Bigram' + '\\t\\t\\t' + 'Count' + '\\t' + 'Probability' + '\\n')\n",
        "\n",
        "\tfor bigrams in listOfBigrams:\n",
        "\t\tfile.write(str(bigrams) + ' : ' + str(bigramCounts[bigrams])\n",
        "\t\t\t\t   + ' : ' + str(listOfProb[bigrams]) + '\\n')\n",
        "\n",
        "\tfile.close()\n",
        "\n",
        "\treturn listOfProb, cStar"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI87ybih5rGx"
      },
      "source": [
        "# Main Program\n",
        "\n",
        "# Create a list of bigrams and get frequencies of unigrams and bigrams\n",
        "listOfBigrams, unigramCounts, bigramCounts = createBigram(data_words_train)\n",
        "\n",
        "# Calculate bigram probabilities\n",
        "bigramProb = calcBigramProb(listOfBigrams, unigramCounts, bigramCounts)\n",
        "\n",
        "# Apply Add-1 Smoothing and calculate probabilities and get reconstructed count of bigrams\n",
        "bigramAddOne, addOneCstar = bigramWithAddOneSmoothing(listOfBigrams, unigramCounts, bigramCounts)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb7mRgWm58JW",
        "outputId": "59828f81-4fd5-4185-87d4-7f2b4b201d0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input = 'we must be very careful'\n",
        "\n",
        "inputList = [] # list to store bigrams\n",
        "\n",
        "for i in range(len(input.split())-1):\n",
        "  inputList.append((input.split()[i], input.split()[i+1]))\n",
        "inputList"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('we', 'must'), ('must', 'be'), ('be', 'very'), ('very', 'careful')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6u-wtkq5_ht",
        "outputId": "592e84a9-fb7b-4d35-eefc-3f1c0e89a573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Open a file to write output\n",
        "output1 = open('bigramProb-OUTPUT.txt', 'w')\n",
        "\n",
        "# initial probability of a sentence\n",
        "outputProb1 = 1\n",
        "\n",
        "output1.write('Bigram\\t\\t\\t\\t' + 'Count\\t\\t\\t\\t' + 'Probability\\n\\n')\n",
        "\n",
        "for i in range(len(inputList)):\n",
        "\n",
        "  # if bigram is present in the model, get updated probability\n",
        "  if inputList[i] in bigramProb:\n",
        "    # write bigram, its count and probability to the file\n",
        "    output1.write(str(inputList[i]) + '\\t\\t' + str(bigramCounts[inputList[i]]) + '\\t\\t' + str(bigramProb[inputList[i]]) + '\\n')\n",
        "    # multiply with probability of a current bigram\n",
        "    outputProb1 *= bigramProb[inputList[i]]\n",
        "\n",
        "  # if bigram is not present in the model, sentence probability is zero\n",
        "  else:\n",
        "    output1.write(str(inputList[i]) + '\\t\\t\\t' + str(0) + '\\t\\t\\t' + str(0) + '\\n')\n",
        "    outputProb1 *= 0\n",
        "\n",
        "output1.write('\\n' + 'Probablility = ' + str(outputProb1))\n",
        "outputProb1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.8076159793430567e-07"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ8k8E2h6EC-",
        "outputId": "4139d736-b62b-46a3-d79b-d8efde63967a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Open a file to write output\n",
        "output2 = open('addOneSmoothing-OUTPUT.txt', 'w')\n",
        "\n",
        "# initial probability of a sentence\n",
        "outputProb2 = 1\n",
        "\n",
        "output2.write('Bigram\\t\\t\\t\\t' + 'Count\\t\\t\\t\\t' + 'Probability\\n\\n')\n",
        "\n",
        "for i in range(len(inputList)):\n",
        "\n",
        "  # if bigram is present in the model, get updated probability\n",
        "  if inputList[i] in bigramAddOne:\n",
        "    # Update probability of the sentence\n",
        "    outputProb2 *= bigramAddOne[inputList[i]]\n",
        "\n",
        "    output2.write(str(inputList[i]) + '\\t\\t' + str(addOneCstar[inputList[i]]) + '\\t\\t' + str(bigramAddOne[inputList[i]]) + '\\n')\n",
        "\n",
        "  # if bigram is not present in the model, use unigram counts to get estimated probability\n",
        "  else:\n",
        "    # if first word in a bigram is not present in unigrams, add with with count 1\n",
        "    if inputList[i][0] not in unigramCounts:\n",
        "      unigramCounts[inputList[i][0]] = 1\n",
        "    \n",
        "    # calculate probability of that word\n",
        "    prob = (1) / (unigramCounts[inputList[i][0]] + len(unigramCounts))\n",
        "\n",
        "    # # reconstructed count for the bigram\n",
        "    addOneCStar = 1 * unigramCounts[inputList[i][0]] / (unigramCounts[inputList[i][0]] + len(unigramCounts))\n",
        "    \n",
        "    # Update probability of the sentence\n",
        "    outputProb2 *= prob\n",
        "\n",
        "    output2.write(str(inputList[i]) + '\\t' + str(addOneCStar) + '\\t' + str(prob) + '\\n')\n",
        "\n",
        "output2.write('\\n' + 'Probablility = ' + str(outputProb2))\n",
        "outputProb2"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.2254340301928457e-14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZCr_7uN6IYz",
        "outputId": "70a3f54c-323d-40d2-e93b-9c52736fc8fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# input sentence\n",
        "print(input)\n",
        "\n",
        "# list of bigrams\n",
        "print(inputList)\n",
        "\n",
        "# probability given by simple bigram model\n",
        "print ('Bigram Model: ', outputProb1)\n",
        "\n",
        "# probability given by bigram model with add-1 smoothing\n",
        "print ('Add One: ', outputProb2)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "we must be very careful\n",
            "[('we', 'must'), ('must', 'be'), ('be', 'very'), ('very', 'careful')]\n",
            "Bigram Model:  2.8076159793430567e-07\n",
            "Add One:  4.2254340301928457e-14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnZ7iDX-6Liy",
        "outputId": "dced3028-2111-4ff5-f857-4641389d31c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def sentence_prob_with_next_word(next_word):\n",
        "  outputProb = 1\n",
        "  new_bigram = (input.split()[-1], next_word)\n",
        "  if new_bigram in bigramAddOne:\n",
        "    outputProb *= bigramAddOne[new_bigram]\n",
        "  else:\n",
        "    if new_bigram[0] not in unigramCounts:\n",
        "      unigramCounts[new_bigram[0]] = 1\n",
        "    prob = (1) / (unigramCounts[new_bigram[0]] + len(unigramCounts))\n",
        "    outputProb *= prob\n",
        "  return outputProb\n",
        "input = 'the investors are'\n",
        "possible_words = ['cheated', 'happy', 'smart', 'afraid']\n",
        "\n",
        "inputList = []\n",
        "outputProb = 1\n",
        "\n",
        "for i in range(len(input.split())-1):\n",
        "  inputList.append((input.split()[i], input.split()[i+1]))\n",
        "\n",
        "\n",
        "for i in range(len(inputList)):\n",
        "\n",
        "  if inputList[i] in bigramAddOne:\n",
        "    outputProb *= bigramAddOne[inputList[i]]\n",
        "  else:\n",
        "    if inputList[i][0] not in unigramCounts:\n",
        "      unigramCounts[inputList[i][0]] = 1\n",
        "    prob = (1) / (unigramCounts[inputList[i][0]] + len(unigramCounts))\n",
        "    outputProb *= prob\n",
        "\n",
        "max_prob = 0\n",
        "index_of_next_word = -1\n",
        "for i, word in enumerate(possible_words):\n",
        "  final_prob = outputProb * sentence_prob_with_next_word(word)\n",
        "  if final_prob > max_prob:\n",
        "    max_prob = final_prob\n",
        "    index_of_next_word = i\n",
        "\n",
        "print('Next Word:', possible_words[index_of_next_word])\n",
        "print('Output Sentece:', input, possible_words[index_of_next_word])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Next Word: happy\n",
            "Output Sentece: the investors are happy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zdtN2r96oAV",
        "outputId": "ba5aa12b-af62-40ec-ccab-893875f3b064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "input1 = 'the market is very happy these days'\n",
        "input2 = 'market is the happy these very days'\n",
        "\n",
        "\n",
        "inputList1 = []\n",
        "inputList2 = []\n",
        "\n",
        "\n",
        "outputProb1 = 1\n",
        "outputProb2 = 1\n",
        "\n",
        "\n",
        "for i in range(len(input1.split())-1):\n",
        "  inputList1.append((input1.split()[i], input1.split()[i+1]))\n",
        "\n",
        "for i in range(len(input2.split())-1):\n",
        "  inputList2.append((input2.split()[i], input2.split()[i+1]))\n",
        "\n",
        "\n",
        "for i in range(len(inputList1)):\n",
        "  if inputList1[i] in bigramAddOne:\n",
        "    outputProb1 *= bigramAddOne[inputList1[i]]\n",
        "  else:\n",
        "    if inputList1[i][0] not in unigramCounts:\n",
        "      unigramCounts[inputList1[i][0]] = 1\n",
        "    prob1 = (1) / (unigramCounts[inputList1[i][0]] + len(unigramCounts))\n",
        "    outputProb1 *= prob1\n",
        "\n",
        "\n",
        "for i in range(len(inputList2)):\n",
        "  if inputList2[i] in bigramAddOne:\n",
        "    outputProb2 *= bigramAddOne[inputList2[i]]\n",
        "  else:\n",
        "    if inputList2[i][0] not in unigramCounts:\n",
        "      unigramCounts[inputList2[i][0]] = 1\n",
        "    prob2 = (1) / (unigramCounts[inputList2[i][0]] + len(unigramCounts))\n",
        "    outputProb2 *= prob2\n",
        "\n",
        "print (input1, ':', outputProb1)\n",
        "print (input2, ':', outputProb2)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the market is very happy these days : 3.0787233025784113e-22\n",
            "market is the happy these very days : 2.5840603259051406e-24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnQttGJp6xRq",
        "outputId": "244137c8-d91c-4c0a-ad5d-f2e1a1283939",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# initial word\n",
        "text = [\"there\"]\n",
        "\n",
        "sentence_finished = False\n",
        " \n",
        "while not sentence_finished:\n",
        "  # select a random probability threshold  \n",
        "  r = random.random()\n",
        "  accumulator = 0.0\n",
        "\n",
        "  for pair in bigramProb.keys():\n",
        "    if pair[0] == text[-1]:\n",
        "      accumulator += bigramProb[pair]\n",
        "      # select words that are above the probability threshold\n",
        "      if accumulator >= r:\n",
        "          text.append(pair[1])\n",
        "          break\n",
        "\n",
        "  if text[-1] == 'None':\n",
        "    sentence_finished = True\n",
        "  if len(text) > 20:\n",
        "    sentence_finished = True\n",
        " \n",
        "print (' '.join([t for t in text if t]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there was an affiliate Rank Xerox Corp said . 2 pct next six weeks in cash for the country . Exports\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4DsqyjR6zFt",
        "outputId": "f97225dd-3d15-4946-86b1-6eafb6beaf1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-de0e8fadeb58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0maccumulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mtpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrigramProb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtpl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtpl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0maccumulator\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrigramProb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtpl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trigramProb' is not defined"
          ]
        }
      ]
    }
  ]
}